WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1766091813.519085   19299 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO] Training log initialized: /home/thunderboltdy/ai-stocks/python-ai-service/training_logs/AAPL_regressor_20251218_220337.log
[INFO] Starting regressor training for AAPL
[INFO] Arguments: epochs=100, batch_size=512, sequence_length=90, seed=42
W0000 00:00:1766091817.296866   19299 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
[GPU] Found 1 GPU(s): ['/physical_device:GPU:0']
[GPU] Memory growth enabled
[GPU] Using float32 for training (mixed precision disabled for stability)

======================================================================
  TRAINING 1-DAY REGRESSOR: AAPL
======================================================================

Target scaler: RobustScaler (clipped to Â±0.15)
Log targets: False | Target noise std: 0.0001
Multi-task learning: True
Loss: huber (quantile=n/a)
ðŸ›¡ï¸  ANTI-COLLAPSE LOSS: ENABLED (AntiCollapseDirectionalLoss - prevents variance collapse)
Variance regularization: ENABLED (weight=0.5)
Feature selection: DISABLED (using all features)

[DATA] Loading data...
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
[INFO] [OK] Feature count validated: 147 features
   [OK] Loaded from cache: 11345 samples, 147 features
[INFO] Using all 147 features
   [OK] Using 1-DAY horizon (research optimal)
   [OK] Using 90-day sequences (quarterly context)

[DATA] Validating target distribution...
[INFO] 
[INFO] ============================================================
[INFO] TARGET DISTRIBUTION CHECK
[INFO] ============================================================
[INFO]    Positive: 50.0% (5,669 samples) | mean: +1.96%
[INFO]    Negative: 46.8% (5,305 samples) | mean: -1.95%
[INFO]    Zero:     3.3% (371 samples)
[INFO]    Overall:  mean=+0.070%, std=2.805%
[INFO] 
[INFO]    Percentiles:
[INFO]       10th: -2.826%
[INFO]       25th: -1.253%
[INFO]       50th: +0.000% (median)
[INFO]       75th: +1.414%
[INFO]       90th: +3.020%
[INFO] 
[INFO] [OK] Distribution is balanced
[INFO] ============================================================
[INFO]    [OK] Target distribution metadata saved to /home/thunderboltdy/ai-stocks/python-ai-service/saved_models/AAPL/target_distribution.json
W0000 00:00:1766091818.141916   19299 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
I0000 00:00:1766091818.410911   19299 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Ti, pci bus id: 0000:2b:00.0, compute capability: 12.0a
I0000 00:00:1766091820.303723   19391 cuda_dnn.cc:461] Loaded cuDNN version 91002
Traceback (most recent call last):
  File "/home/thunderboltdy/ai-stocks/python-ai-service/training/train_1d_regressor_final.py", line 2833, in <module>
    main()
  File "/home/thunderboltdy/ai-stocks/python-ai-service/training/train_1d_regressor_final.py", line 2803, in main
    model = train_1d_regressor(
  File "/home/thunderboltdy/ai-stocks/python-ai-service/training/train_1d_regressor_final.py", line 1956, in train_1d_regressor
    model = create_multitask_regressor(
  File "/home/thunderboltdy/ai-stocks/python-ai-service/training/train_1d_regressor_final.py", line 1155, in create_multitask_regressor
    x = x + base.pos_encoding[:, :sequence_length, :]
AttributeError: 'LSTMTransformerPaper' object has no attribute 'pos_encoding'
   [OK] Target distribution validation passed
   [OK] Using precomputed target scaling from prepare_training_data. Scaled length: 11345

=== Target Scaling Verification ===
Original target range: [-0.731248, 0.286892]
Scaled target range: [-2.490687, 2.509210]
Scaled target stats: mean=0.000000, std=1.000000
Target scaler: (parameters not accessible)
Inverse transform roundtrip error: 0.00099141

   Train: 9004, Val: 2252

[TARGET] Preparing multi-task targets...

[INFO] Multi-task target distribution:
   Sign classes - Down: 4647 (51.6%), Flat: 6 (0.1%), Up: 4351 (48.3%)
   Volatility range: [0.0008, 0.2450]
   [OK] Sign classes prepared (3 classes: down/flat/up)
   [OK] Volatility targets prepared and scaled

[BUILD] Building model...
   Multi-task architecture: 3 output heads (magnitude + sign + volatility)

[FAIL] FATAL ERROR during regressor training: 'LSTMTransformerPaper' object has no attribute 'pos_encoding'
