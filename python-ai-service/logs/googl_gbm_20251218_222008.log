2025-12-18 22:20:10,927 - __main__ - INFO - Using seed: 42
2025-12-18 22:20:10,928 - __main__ - INFO - Preparing GBM data for GOOGL...
2025-12-18 22:20:10,928 - data.cache_manager - INFO - DataCacheManager initialized: cache
2025-12-18 22:20:10,929 - data.cache_manager - INFO - ðŸ“Š Fetching fresh data for GOOGL...
2025-12-18 22:20:10,929 - data.cache_manager - INFO -   1/3 Fetching OHLCV data...
2025-12-18 22:20:10,929 - data.data_fetcher - INFO - Fetching data for GOOGL (period=max)
2025-12-18 22:20:11,425 - data.data_fetcher - INFO - âœ“ Fetched 5369 days of data for GOOGL
2025-12-18 22:20:11,425 - data.cache_manager - INFO -   2/3 Engineering features (sentiment=enabled)...
2025-12-18 22:23:28,763 - data.cache_manager - INFO - ðŸ“° Fetching fresh news for GOOGL...
2025-12-18 22:23:28,765 - data.news_fetcher - ERROR - finnhub-python library not found. Install with:
pip install finnhub-python>=2.4.0
2025-12-18 22:23:28,765 - data.cache_manager - ERROR - Failed to fetch news for GOOGL: No module named 'finnhub'
2025-12-18 22:23:28,766 - data.news_fetcher - ERROR - finnhub-python library not found. Install with:
pip install finnhub-python>=2.4.0
2025-12-18 22:23:28,767 - data.feature_engineer - WARNING - Direct news fetch failed for GOOGL: No module named 'finnhub'
/home/thunderboltdy/ai-stocks/python-ai-service/data/feature_engineer.py:1229: UserWarning: Feature engineering verified for look-ahead bias. All .shift() calls use positive or zero values. All .rolling() windows use past data only.
  warnings.warn(
2025-12-18 22:23:28,881 - data.feature_engineer - INFO - Cleaning features and handling NaN values (no look-ahead)...
2025-12-18 22:23:28,887 - data.feature_engineer - WARNING - Filling remaining NaNs with neutral values: {'returns': 1, 'log_returns': 1, 'volatility_5d': 5, 'volatility_20d': 20, 'rsi': 13, 'macd': 25, 'macd_signal': 33, 'macd_histogram': 33, 'stoch_k': 13, 'stoch_d': 15, 'sma_10': 9, 'sma_20': 19, 'sma_50': 49, 'price_to_sma20': 19, 'price_to_sma50': 49, 'sma_10_20_cross': 19, 'bb_upper': 19, 'bb_lower': 19, 'bb_width': 19, 'bb_position': 19, 'realized_vol_20d': 2, 'rv_iv_spread': 2, 'volume_sma': 19, 'volume_ratio': 19, 'momentum_1d': 1, 'momentum_5d': 5, 'momentum_20d': 20, 'rate_of_change_10d': 10, 'vol_ratio_5_20': 20, 'volume_price_trend': 19, 'accumulation_distribution': 38, 'return_lag_1': 2, 'return_lag_2': 3, 'return_lag_5': 6, 'velocity_5d': 5, 'velocity_10d': 10, 'velocity_20d': 20, 'acceleration_5d': 10, 'rsi_velocity': 18, 'volume_velocity': 5, 'gap_up': 1, 'gap_down': 1, 'rsi_momentum': 18, 'momentum_divergence_5d': 18, 'momentum_divergence_20d': 33, 'distance_to_fib_382': 20, 'distance_to_fib_500': 20, 'distance_to_fib_618': 20, 'vwap_deviation': 19, 'vwap_volume_ratio': 19, 'vwap_band_position': 19, 'vw_momentum_5d': 5, 'vw_momentum_20d': 20}
2025-12-18 22:23:28,909 - data.feature_engineer - INFO - [OK] All NaN values handled. Shape: (5369, 162)
2025-12-18 22:23:28,920 - data.feature_engineer - INFO - [AUDIT] Feature Audit for GOOGL:
2025-12-18 22:23:28,920 - data.feature_engineer - INFO -    Actual: 155 features
2025-12-18 22:23:28,920 - data.feature_engineer - INFO -    Expected: 147 features
2025-12-18 22:23:28,920 - data.feature_engineer - WARNING -    [WARN] Extra features (8): ['stoch_k_low_vol', 'bb_position_high_vol', 'momentum_high_vol', 'momentum_low_vol', 'volatility_regime_low', 'regime_normal_vol', 'volatility_regime_high', 'stoch_k_high_vol']
2025-12-18 22:23:28,920 - data.feature_engineer - INFO -    Categories: {'price_momentum': 19, 'volatility': 42, 'volume': 21, 'trend': 18, 'pattern': 5, 'support_resistance': 11, 'sentiment': 17, 'regime': 13, 'divergence': 21, 'new_v31': 21}
2025-12-18 22:23:28,940 - data.feature_engineer - INFO - [OK] Feature engineering complete: (5369, 152) with EXACTLY 147 features
2025-12-18 22:23:28,940 - data.feature_engineer - INFO - [OK] Feature engineering complete: (5369, 152)
2025-12-18 22:23:28,943 - data.cache_manager - INFO -   3/3 Preparing training data...
2025-12-18 22:23:29,366 - data.cache_manager - INFO - ðŸ” Validating data alignment...
2025-12-18 22:23:29,368 - data.cache_manager - INFO - âœ“ Sequence alignment validated (20 samples checked)
2025-12-18 22:23:29,368 - data.cache_manager - INFO - âœ“ Alignment validation passed
2025-12-18 22:23:29,368 - data.cache_manager - WARNING - Feature count mismatch in prepared data: expected=147, got=150
2025-12-18 22:23:29,368 - data.cache_manager - INFO -   Raw shape: (5369, 7)
2025-12-18 22:23:29,368 - data.cache_manager - INFO -   Engineered shape: (5369, 152)
2025-12-18 22:23:29,368 - data.cache_manager - INFO -   Prepared shape: (5367, 155)
2025-12-18 22:23:29,368 - data.cache_manager - INFO -   Index alignment: 5367 rows preserved from 5369
2025-12-18 22:23:29,382 - data.cache_manager - INFO - âœ“ Cached data for GOOGL: (5367, 155)
2025-12-18 22:23:29,382 - __main__ - INFO - Using cached data: (5367, 155)
2025-12-18 22:23:29,382 - __main__ - INFO - Found 14 sentiment features - ensure they are properly lagged
2025-12-18 22:23:29,382 - __main__ - INFO - âœ“ No look-ahead leakage detected in feature names
2025-12-18 22:23:29,384 - __main__ - INFO - Target range after clipping: [-0.1000, 0.1000]
2025-12-18 22:23:29,386 - __main__ - INFO - Data shape: X=(5367, 147), y=(5367,)
2025-12-18 22:23:29,386 - __main__ - INFO - 
============================================================
2025-12-18 22:23:29,386 - __main__ - INFO - Training XGBoost...
2025-12-18 22:23:29,386 - __main__ - INFO - ============================================================
2025-12-18 22:23:29,386 - __main__ - INFO - Walk-forward CV: 5 splits, test_size=60, gap=1
2025-12-18 22:23:29,386 - __main__ - INFO - Total samples: 5367, min train size: 894
2025-12-18 22:23:29,386 - __main__ - INFO - 
--- Fold 1/5 ---
2025-12-18 22:23:29,386 - __main__ - INFO - Train: 5066 samples (indices 0-5065)
2025-12-18 22:23:29,386 - __main__ - INFO - Val: 60 samples (indices 5067-5126)
2025-12-18 22:23:30,029 - __main__ - INFO -   XGBoost early stopped at iteration 140
2025-12-18 22:23:30,031 - __main__ - INFO -   MSE: 0.000335, MAE: 0.013578, RÂ²: 0.0093
2025-12-18 22:23:30,031 - __main__ - INFO -   Direction Acc: 0.6333, IC: 0.1791
2025-12-18 22:23:30,031 - __main__ - INFO -   Prediction std: 0.001971
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:30,286 - __main__ - INFO - âœ“ Training curve saved: logs/xgb_training_curve_GOOGL_fold1.png
2025-12-18 22:23:30,286 - __main__ - INFO - 
--- Fold 2/5 ---
2025-12-18 22:23:30,286 - __main__ - INFO - Train: 5126 samples (indices 0-5125)
2025-12-18 22:23:30,286 - __main__ - INFO - Val: 60 samples (indices 5127-5186)
2025-12-18 22:23:32,890 - __main__ - INFO -   MSE: 0.000558, MAE: 0.018462, RÂ²: -0.2848
2025-12-18 22:23:32,890 - __main__ - INFO -   Direction Acc: 0.4333, IC: 0.0319
2025-12-18 22:23:32,890 - __main__ - INFO -   Prediction std: 0.006583
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:33,124 - __main__ - INFO - âœ“ Training curve saved: logs/xgb_training_curve_GOOGL_fold2.png
2025-12-18 22:23:33,124 - __main__ - INFO - 
--- Fold 3/5 ---
2025-12-18 22:23:33,124 - __main__ - INFO - Train: 5186 samples (indices 0-5185)
2025-12-18 22:23:33,124 - __main__ - INFO - Val: 60 samples (indices 5187-5246)
2025-12-18 22:23:35,576 - __main__ - INFO -   MSE: 0.000654, MAE: 0.019204, RÂ²: -0.1055
2025-12-18 22:23:35,576 - __main__ - INFO -   Direction Acc: 0.5167, IC: 0.0992
2025-12-18 22:23:35,576 - __main__ - INFO -   Prediction std: 0.008272
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:35,912 - __main__ - INFO - âœ“ Training curve saved: logs/xgb_training_curve_GOOGL_fold3.png
2025-12-18 22:23:35,912 - __main__ - INFO - 
--- Fold 4/5 ---
2025-12-18 22:23:35,912 - __main__ - INFO - Train: 5246 samples (indices 0-5245)
2025-12-18 22:23:35,912 - __main__ - INFO - Val: 60 samples (indices 5247-5306)
2025-12-18 22:23:38,386 - __main__ - WARNING -   âš ï¸ Fold 4 SEVERE BIAS: 8.3% positive
2025-12-18 22:23:38,387 - __main__ - INFO -   MSE: 0.000493, MAE: 0.016156, RÂ²: -0.8390
2025-12-18 22:23:38,387 - __main__ - INFO -   Direction Acc: 0.4167, IC: 0.1681
2025-12-18 22:23:38,387 - __main__ - INFO -   Prediction std: 0.008063
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:38,626 - __main__ - INFO - âœ“ Training curve saved: logs/xgb_training_curve_GOOGL_fold4.png
2025-12-18 22:23:38,626 - __main__ - INFO - 
--- Fold 5/5 ---
2025-12-18 22:23:38,627 - __main__ - INFO - Train: 5306 samples (indices 0-5305)
2025-12-18 22:23:38,627 - __main__ - INFO - Val: 60 samples (indices 5307-5366)
2025-12-18 22:23:41,075 - __main__ - INFO -   MSE: 0.000439, MAE: 0.017072, RÂ²: -0.2124
2025-12-18 22:23:41,075 - __main__ - INFO -   Direction Acc: 0.4833, IC: -0.1851
2025-12-18 22:23:41,076 - __main__ - INFO -   Prediction std: 0.005141
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:41,311 - __main__ - INFO - âœ“ Training curve saved: logs/xgb_training_curve_GOOGL_fold5.png
2025-12-18 22:23:41,313 - __main__ - INFO - 
=== XGB CV Summary ===
2025-12-18 22:23:41,313 - __main__ - INFO - MSE: 0.000496 Â± 0.000120
2025-12-18 22:23:41,313 - __main__ - INFO - MAE: 0.016895 Â± 0.002201
2025-12-18 22:23:41,313 - __main__ - INFO - RÂ²: -0.2865 Â± 0.3282
2025-12-18 22:23:41,313 - __main__ - INFO - Direction Acc: 0.4967 Â± 0.0861
2025-12-18 22:23:41,313 - __main__ - INFO - IC: 0.0586 Â± 0.1486
2025-12-18 22:23:41,313 - __main__ - INFO - Avg prediction std: 0.006006
2025-12-18 22:23:41,316 - __main__ - INFO - Training final XGB model on 5367 samples...
2025-12-18 22:23:41,470 - __main__ - INFO - Final XGBoost model: best iteration = 0
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:41,730 - __main__ - INFO - âœ“ Training curve saved: logs/xgb_training_curve_GOOGL_final.png
2025-12-18 22:23:41,732 - __main__ - INFO - Prediction stats: mean=0.000859, std=0.000176
2025-12-18 22:23:41,732 - __main__ - INFO - Prediction distribution: 99.4% positive, 0.6% negative
2025-12-18 22:23:41,732 - __main__ - INFO - Final IC: 0.2267, Direction Acc: 0.5310
2025-12-18 22:23:41,732 - __main__ - WARNING - âš ï¸ VARIANCE COLLAPSE DETECTED: Predictions have near-zero variance
2025-12-18 22:23:41,732 - __main__ - WARNING -    This means the model is outputting constant values
2025-12-18 22:23:41,732 - __main__ - WARNING -    Root causes: early stopping too aggressive, huber_delta too large, or data issues
2025-12-18 22:23:41,733 - __main__ - WARNING - âš ï¸ Predictions are biased: 99.4% positive, 0.6% negative
2025-12-18 22:23:41,751 - __main__ - INFO - XGBoost model saved to saved_models/GOOGL/gbm/xgb_reg.joblib
2025-12-18 22:23:41,751 - __main__ - INFO - 
============================================================
2025-12-18 22:23:41,751 - __main__ - INFO - Training LightGBM...
2025-12-18 22:23:41,751 - __main__ - INFO - ============================================================
2025-12-18 22:23:41,751 - __main__ - INFO - Walk-forward CV: 5 splits, test_size=60, gap=1
2025-12-18 22:23:41,751 - __main__ - INFO - Total samples: 5367, min train size: 894
2025-12-18 22:23:41,751 - __main__ - INFO - 
--- Fold 1/5 ---
2025-12-18 22:23:41,751 - __main__ - INFO - Train: 5066 samples (indices 0-5065)
2025-12-18 22:23:41,751 - __main__ - INFO - Val: 60 samples (indices 5067-5126)
2025-12-18 22:23:42,060 - __main__ - INFO -   LightGBM trained 97 trees
/home/thunderboltdy/miniconda3/envs/ai-stocks/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names
  warnings.warn(
2025-12-18 22:23:42,062 - __main__ - INFO -   LightGBM Diagnostics (Fold 1):
2025-12-18 22:23:42,063 - __main__ - INFO -     Prediction std: 0.001675
2025-12-18 22:23:42,063 - __main__ - INFO -     Positive predictions: 75.0%
2025-12-18 22:23:42,063 - __main__ - INFO -     Mean prediction: 0.000447
2025-12-18 22:23:42,064 - __main__ - INFO -   MSE: 0.000338, MAE: 0.013692, RÂ²: -0.0001
2025-12-18 22:23:42,064 - __main__ - INFO -   Direction Acc: 0.5667, IC: 0.1198
2025-12-18 22:23:42,064 - __main__ - INFO -   Prediction std: 0.001675
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:42,326 - __main__ - INFO - âœ“ Training curve saved: logs/lgb_training_curve_GOOGL_fold1.png
2025-12-18 22:23:42,327 - __main__ - INFO - 
--- Fold 2/5 ---
2025-12-18 22:23:42,327 - __main__ - INFO - Train: 5126 samples (indices 0-5125)
2025-12-18 22:23:42,327 - __main__ - INFO - Val: 60 samples (indices 5127-5186)
2025-12-18 22:23:43,565 - __main__ - INFO -   LightGBM trained 1000 trees
/home/thunderboltdy/miniconda3/envs/ai-stocks/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names
  warnings.warn(
2025-12-18 22:23:43,567 - __main__ - INFO -   LightGBM Diagnostics (Fold 2):
2025-12-18 22:23:43,567 - __main__ - INFO -     Prediction std: 0.006143
2025-12-18 22:23:43,567 - __main__ - INFO -     Positive predictions: 80.0%
2025-12-18 22:23:43,567 - __main__ - INFO -     Mean prediction: 0.003528
2025-12-18 22:23:43,569 - __main__ - INFO -   MSE: 0.000518, MAE: 0.017907, RÂ²: -0.1919
2025-12-18 22:23:43,569 - __main__ - INFO -   Direction Acc: 0.4167, IC: 0.0045
2025-12-18 22:23:43,569 - __main__ - INFO -   Prediction std: 0.006143
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:43,818 - __main__ - INFO - âœ“ Training curve saved: logs/lgb_training_curve_GOOGL_fold2.png
2025-12-18 22:23:43,818 - __main__ - INFO - 
--- Fold 3/5 ---
2025-12-18 22:23:43,818 - __main__ - INFO - Train: 5186 samples (indices 0-5185)
2025-12-18 22:23:43,818 - __main__ - INFO - Val: 60 samples (indices 5187-5246)
2025-12-18 22:23:45,175 - __main__ - INFO -   LightGBM trained 1000 trees
/home/thunderboltdy/miniconda3/envs/ai-stocks/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names
  warnings.warn(
2025-12-18 22:23:45,177 - __main__ - INFO -   LightGBM Diagnostics (Fold 3):
2025-12-18 22:23:45,177 - __main__ - INFO -     Prediction std: 0.007140
2025-12-18 22:23:45,177 - __main__ - INFO -     Positive predictions: 35.0%
2025-12-18 22:23:45,177 - __main__ - INFO -     Mean prediction: -0.001926
2025-12-18 22:23:45,178 - __main__ - INFO -   MSE: 0.000634, MAE: 0.018811, RÂ²: -0.0729
2025-12-18 22:23:45,179 - __main__ - INFO -   Direction Acc: 0.5167, IC: 0.0657
2025-12-18 22:23:45,179 - __main__ - INFO -   Prediction std: 0.007140
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:45,424 - __main__ - INFO - âœ“ Training curve saved: logs/lgb_training_curve_GOOGL_fold3.png
2025-12-18 22:23:45,424 - __main__ - INFO - 
--- Fold 4/5 ---
2025-12-18 22:23:45,424 - __main__ - INFO - Train: 5246 samples (indices 0-5245)
2025-12-18 22:23:45,424 - __main__ - INFO - Val: 60 samples (indices 5247-5306)
2025-12-18 22:23:47,070 - __main__ - INFO -   LightGBM trained 1000 trees
/home/thunderboltdy/miniconda3/envs/ai-stocks/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names
  warnings.warn(
2025-12-18 22:23:47,073 - __main__ - INFO -   LightGBM Diagnostics (Fold 4):
2025-12-18 22:23:47,073 - __main__ - INFO -     Prediction std: 0.006052
2025-12-18 22:23:47,073 - __main__ - INFO -     Positive predictions: 16.7%
2025-12-18 22:23:47,073 - __main__ - INFO -     Mean prediction: -0.005209
2025-12-18 22:23:47,074 - __main__ - INFO -   MSE: 0.000392, MAE: 0.013470, RÂ²: -0.4621
2025-12-18 22:23:47,074 - __main__ - INFO -   Direction Acc: 0.5000, IC: 0.1542
2025-12-18 22:23:47,074 - __main__ - INFO -   Prediction std: 0.006052
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:47,318 - __main__ - INFO - âœ“ Training curve saved: logs/lgb_training_curve_GOOGL_fold4.png
2025-12-18 22:23:47,318 - __main__ - INFO - 
--- Fold 5/5 ---
2025-12-18 22:23:47,318 - __main__ - INFO - Train: 5306 samples (indices 0-5305)
2025-12-18 22:23:47,318 - __main__ - INFO - Val: 60 samples (indices 5307-5366)
2025-12-18 22:23:48,558 - __main__ - INFO -   LightGBM trained 1000 trees
/home/thunderboltdy/miniconda3/envs/ai-stocks/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names
  warnings.warn(
2025-12-18 22:23:48,560 - __main__ - INFO -   LightGBM Diagnostics (Fold 5):
2025-12-18 22:23:48,560 - __main__ - INFO -     Prediction std: 0.005917
2025-12-18 22:23:48,560 - __main__ - INFO -     Positive predictions: 88.3%
2025-12-18 22:23:48,560 - __main__ - INFO -     Mean prediction: 0.007404
2025-12-18 22:23:48,561 - __main__ - INFO -   MSE: 0.000428, MAE: 0.016712, RÂ²: -0.1813
2025-12-18 22:23:48,561 - __main__ - INFO -   Direction Acc: 0.5000, IC: -0.0639
2025-12-18 22:23:48,562 - __main__ - INFO -   Prediction std: 0.005917
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:48,801 - __main__ - INFO - âœ“ Training curve saved: logs/lgb_training_curve_GOOGL_fold5.png
2025-12-18 22:23:48,803 - __main__ - INFO - 
=== LGB CV Summary ===
2025-12-18 22:23:48,803 - __main__ - INFO - MSE: 0.000462 Â± 0.000117
2025-12-18 22:23:48,803 - __main__ - INFO - MAE: 0.016118 Â± 0.002434
2025-12-18 22:23:48,803 - __main__ - INFO - RÂ²: -0.1816 Â± 0.1757
2025-12-18 22:23:48,803 - __main__ - INFO - Direction Acc: 0.5000 Â± 0.0540
2025-12-18 22:23:48,803 - __main__ - INFO - IC: 0.0561 Â± 0.0878
2025-12-18 22:23:48,803 - __main__ - INFO - Avg prediction std: 0.005385
2025-12-18 22:23:48,804 - __main__ - INFO - Training final LGB model on 5367 samples...
2025-12-18 22:23:48,949 - __main__ - INFO - Phase 1 complete: best_iter=1, using 200 trees for final model
2025-12-18 22:23:48,949 - __main__ - INFO - Phase 2 config: {'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 6, 'num_leaves': 31, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_samples': 20, 'reg_alpha': 0.005, 'reg_lambda': 0.01, 'min_split_gain': 0.0, 'random_state': 42, 'n_jobs': -1, 'objective': 'huber', 'alpha': 0.9, 'metric': ['rmse'], 'verbosity': -1, 'force_col_wise': True, 'deterministic': True}
2025-12-18 22:23:49,172 - __main__ - INFO - Phase 2 complete: Final LightGBM model trained 200 trees
/home/thunderboltdy/ai-stocks/python-ai-service/training/train_gbm_baseline.py:191: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  axes[1].legend()
2025-12-18 22:23:49,397 - __main__ - INFO - âœ“ Training curve saved: logs/lgb_training_curve_GOOGL_final.png
/home/thunderboltdy/miniconda3/envs/ai-stocks/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names
  warnings.warn(
2025-12-18 22:23:49,405 - __main__ - INFO - Prediction stats: mean=0.000834, std=0.005315
2025-12-18 22:23:49,405 - __main__ - INFO - Prediction distribution: 66.6% positive, 33.4% negative
2025-12-18 22:23:49,405 - __main__ - INFO - Final IC: 0.7209, Direction Acc: 0.7034
2025-12-18 22:23:49,419 - __main__ - INFO - LightGBM model saved to saved_models/GOOGL/gbm/lgb_reg.joblib
2025-12-18 22:23:49,421 - __main__ - INFO - 
âœ“ GBM training complete for GOOGL
2025-12-18 22:23:49,421 - __main__ - INFO -   Models saved to: saved_models/GOOGL/gbm
[INFO] Adding volatility spread features for GOOGL...
âœ“ Fetched VIX data: 5368 days
âœ“ Added volatility spread features (latest spread: 95.03%)
[OK] Volatility spread features added (5 new columns)
   Regime distribution - LOW: 2.01%, NORMAL: 88.45%, HIGH: 9.54%
   Current regime: NORMAL_VOL | Regime transitions/year: 6.71
   -> Preparing sentiment features (loads FinBERT + news data on first run, may take a few minutes)...

=== Fetching Sentiment Features for GOOGL ===
Fetching news from 2004-08-19 to 2025-12-18 (7851 days)...
[WARN] No news data available or fetch failed. Using zero-filled sentiment features.

=== Look-Ahead Bias Verification ===
Checking for common look-ahead patterns...
[OK] All shifts use positive or zero values (no negative shifts)
[OK] All rolling windows use past data only
[OK] Forward-looking features only in target labels (handled separately)

=== Feature Quality Check ===
[OK] No features with >5% NaN values
[OK] No inf values (successfully handled)

[WARN] Features with wide ranges (may need clipping):
   rsi: [27.6721, 82.4274] range=54.7553
   macd: [-4.5270, 7.6009] range=12.1279
   macd_signal: [-4.2698, 7.8092] range=12.0790
   stoch_k: [0.9814, 99.5514] range=98.5700
   stoch_d: [5.1888, 96.7501] range=91.5613
   ... and 19 more

Total features: 157
Total samples after cleaning: 5369
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0

=== Feature Count Diagnostic ===
Expected features (count=147). Present feature cols (count=157).
Extra 10 features (will be dropped): ['Dividends', 'Stock Splits', 'regime_normal_vol', 'bb_position_high_vol', 'stoch_k_low_vol', 'stoch_k_high_vol', 'momentum_low_vol', 'momentum_high_vol', 'volatility_regime_low', 'volatility_regime_high']
Dropped unexpected columns: ['Dividends', 'Stock Splits', 'regime_normal_vol', 'bb_position_high_vol', 'stoch_k_low_vol', 'stoch_k_high_vol', 'momentum_low_vol', 'momentum_high_vol', 'volatility_regime_low', 'volatility_regime_high']
Final feature count after auto-fix: 147
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
âœ… Training data prepared:
   Total rows: 5367
   Features: 147
   Targets: ['target_1d']
   Lost rows (NaN): 2

=== Target Statistics (BEFORE clipping) ===
Range: [-0.1237, 0.1823]
Mean: 0.000880, Std: 0.019208
Percentiles: 1%=-0.0526, 99%=0.0544
P1.3: Winsorized 214 values (3.99%)
Clipped 0 values (0.00%)
\n=== Target Statistics (AFTER scaling) ===
Mean: -0.000000 (should be ~0)
Std: 1.000000 (should be ~1)
Range: [-2.66, 2.46]
Saved target engineering diagnostics to: data/target_engineering_comparison.png
Technical features by category (expected sum): 116
Actual technical list length: 113
Difference from canonical 113: 0
Training until validation scores don't improve for 100 rounds
[100]	training's rmse: 0.0167413	validation's rmse: 0.0183993
Early stopping, best iteration is:
[97]	training's rmse: 0.016779	validation's rmse: 0.0183816
[100]	training's rmse: 0.0167217	validation's rmse: 0.021363
[200]	training's rmse: 0.0151772	validation's rmse: 0.021666
[300]	training's rmse: 0.0137901	validation's rmse: 0.0218332
[400]	training's rmse: 0.0125508	validation's rmse: 0.022108
[500]	training's rmse: 0.0114742	validation's rmse: 0.0223477
[600]	training's rmse: 0.0105729	validation's rmse: 0.022445
[700]	training's rmse: 0.00969596	validation's rmse: 0.0224653
[800]	training's rmse: 0.00895496	validation's rmse: 0.0225444
[900]	training's rmse: 0.00828156	validation's rmse: 0.022719
[1000]	training's rmse: 0.00760924	validation's rmse: 0.0227584
[100]	training's rmse: 0.0167206	validation's rmse: 0.0242746
[200]	training's rmse: 0.015133	validation's rmse: 0.024088
[300]	training's rmse: 0.0138577	validation's rmse: 0.0243307
[400]	training's rmse: 0.0127459	validation's rmse: 0.0243039
[500]	training's rmse: 0.0117468	validation's rmse: 0.0244093
[600]	training's rmse: 0.0107212	validation's rmse: 0.0246336
[700]	training's rmse: 0.00991966	validation's rmse: 0.0248199
[800]	training's rmse: 0.0091663	validation's rmse: 0.0249932
[900]	training's rmse: 0.00843464	validation's rmse: 0.02506
[1000]	training's rmse: 0.00780182	validation's rmse: 0.0251873
[100]	training's rmse: 0.0167411	validation's rmse: 0.0177139
[200]	training's rmse: 0.0151224	validation's rmse: 0.0177942
[300]	training's rmse: 0.0138542	validation's rmse: 0.0180391
[400]	training's rmse: 0.0127387	validation's rmse: 0.0184009
[500]	training's rmse: 0.0117504	validation's rmse: 0.0187246
[600]	training's rmse: 0.0108428	validation's rmse: 0.0190518
[700]	training's rmse: 0.0100523	validation's rmse: 0.019398
[800]	training's rmse: 0.00922853	validation's rmse: 0.0196622
[900]	training's rmse: 0.00853253	validation's rmse: 0.0199114
[1000]	training's rmse: 0.00785891	validation's rmse: 0.0198074
[100]	training's rmse: 0.0168999	validation's rmse: 0.019349
[200]	training's rmse: 0.0154027	validation's rmse: 0.0193383
[300]	training's rmse: 0.0140679	validation's rmse: 0.0196216
[400]	training's rmse: 0.0128924	validation's rmse: 0.0197469
[500]	training's rmse: 0.0119534	validation's rmse: 0.0200407
[600]	training's rmse: 0.0110348	validation's rmse: 0.0201634
[700]	training's rmse: 0.0102064	validation's rmse: 0.0203082
[800]	training's rmse: 0.00947993	validation's rmse: 0.0204472
[900]	training's rmse: 0.00872135	validation's rmse: 0.020595
[1000]	training's rmse: 0.00806421	validation's rmse: 0.0206775
Training until validation scores don't improve for 100 rounds
[100]	training's rmse: 0.0158954	validation's rmse: 0.0204973
Early stopping, best iteration is:
[1]	training's rmse: 0.0183546	validation's rmse: 0.0202421

============================================================
TRAINING SUMMARY
============================================================

XGB:
  MSE:  0.000496 Â± 0.000120
  MAE:  0.016895 Â± 0.002201
  RÂ²:   -0.2865 Â± 0.3282
  Dir:  0.4967 Â± 0.0861
  IC:   0.0586 Â± 0.1486

LGB:
  MSE:  0.000462 Â± 0.000117
  MAE:  0.016118 Â± 0.002434
  RÂ²:   -0.1816 Â± 0.1757
  Dir:  0.5000 Â± 0.0540
  IC:   0.0561 Â± 0.0878
